"""
Wall Plane Detection from Depth Maps.

Uses RANSAC plane fitting to identify the dominant wall plane
from a depth map generated by MiDaS.

Memory-optimized for low-memory environments (512MB-1GB).
"""
import logging
import numpy as np

logger = logging.getLogger(__name__)


def detect_wall_plane(
    depth_map: np.ndarray,
    image_width: int,
    image_height: int,
    min_confidence: float = 0.3,
) -> dict:
    """
    Detect the dominant wall plane from a depth map.

    Uses RANSAC to find the largest planar surface, which is typically
    the wall the user photographed.

    Memory-optimized: Uses sampling instead of full array operations.

    Args:
        depth_map: Depth map array (height, width) with values in [0, 1]
        image_width: Original image width
        image_height: Original image height
        min_confidence: Minimum confidence threshold

    Returns:
        Dictionary with:
        - bounds: {top, bottom, left, right} pixel coordinates
        - confidence: float between 0 and 1
    """
    try:
        from sklearn.linear_model import RANSACRegressor
    except ImportError:
        logger.warning('sklearn not available. Using fallback detection.')
        return _fallback_detection(image_width, image_height)

    try:
        h, w = depth_map.shape
        logger.info(f'Wall detection starting: depth map {w}x{h}')

        # Flatten depth map only (avoid creating coordinate grids)
        points_z = depth_map.flatten()

        # Filter out invalid depth values
        valid_mask = (points_z > 0.05) & (points_z < 0.95)
        valid_indices = np.where(valid_mask)[0]
        valid_count = len(valid_indices)

        logger.info(f'Valid depth points: {valid_count}')

        if valid_count < 500:
            logger.warning('Not enough valid depth points')
            return _fallback_detection(image_width, image_height)

        # Use smaller sample for RANSAC to reduce memory
        sample_size = min(3000, valid_count)
        sample_indices = np.random.choice(valid_indices, size=sample_size, replace=False)

        # Convert flat indices to x,y coordinates only for sampled points
        sample_y = sample_indices // w
        sample_x = sample_indices % w

        X = np.column_stack([sample_x, sample_y]).astype(np.float32)
        z = points_z[sample_indices].astype(np.float32)

        # Free memory
        del points_z

        # RANSAC plane fitting: z = ax + by + c
        threshold = np.std(z) * 0.5

        logger.info('Running RANSAC...')
        ransac = RANSACRegressor(
            min_samples=0.1,
            residual_threshold=threshold,
            max_trials=100,  # Reduced for speed/memory
            random_state=42,
        )
        ransac.fit(X, z)

        # Get inliers from sample
        inlier_mask = ransac.inlier_mask_
        confidence = np.sum(inlier_mask) / len(inlier_mask)

        logger.info(f'RANSAC complete. Sample confidence: {confidence:.2%}')

        # Get bounds from inlier points directly (no full mask needed)
        inlier_x = sample_x[inlier_mask]
        inlier_y = sample_y[inlier_mask]

        if len(inlier_x) < 100:
            logger.warning('Too few inliers detected')
            return _fallback_detection(image_width, image_height)

        # Use percentiles to exclude outliers when computing bounds
        x_min = int(np.percentile(inlier_x, 5))
        x_max = int(np.percentile(inlier_x, 95))
        y_min = int(np.percentile(inlier_y, 5))
        y_max = int(np.percentile(inlier_y, 95))

        # Scale bounds to original image size
        scale_x = image_width / w
        scale_y = image_height / h

        bounds = {
            'top': int(y_min * scale_y),
            'bottom': int(y_max * scale_y),
            'left': int(x_min * scale_x),
            'right': int(x_max * scale_x),
        }

        logger.info(f'Wall detected with confidence: {confidence:.2%}, bounds: {bounds}')

        return {
            'bounds': bounds,
            'confidence': float(confidence),
        }

    except Exception as e:
        logger.error(f'Wall detection failed: {e}')
        return _fallback_detection(image_width, image_height)


def _fallback_detection(image_width: int, image_height: int) -> dict:
    """
    Fallback wall detection when ML fails.
    Returns bounds covering most of the image with a margin.
    """
    margin_x = int(image_width * 0.1)
    margin_y = int(image_height * 0.1)

    return {
        'bounds': {
            'top': margin_y,
            'bottom': image_height - margin_y,
            'left': margin_x,
            'right': image_width - margin_x,
        },
        'confidence': 0.0,
    }


def refine_wall_bounds(
    depth_map: np.ndarray,
    initial_bounds: dict,
    image_width: int,
    image_height: int,
) -> dict:
    """
    Refine wall bounds using edge detection.

    This can be used to snap bounds to actual wall edges
    after initial detection or manual selection.

    Args:
        depth_map: Depth map array
        initial_bounds: Initial bounds to refine
        image_width: Original image width
        image_height: Original image height

    Returns:
        Refined bounds dictionary
    """
    try:
        import cv2
    except ImportError:
        return initial_bounds

    try:
        # Convert depth map to uint8 for edge detection
        depth_uint8 = (depth_map * 255).astype(np.uint8)

        # Apply Canny edge detection
        edges = cv2.Canny(depth_uint8, 50, 150)

        # Scale to original image size
        h, w = depth_map.shape
        scale_x = w / image_width
        scale_y = h / image_height

        # Convert bounds to depth map coordinates
        top = int(initial_bounds['top'] * scale_y)
        bottom = int(initial_bounds['bottom'] * scale_y)
        left = int(initial_bounds['left'] * scale_x)
        right = int(initial_bounds['right'] * scale_x)

        # Find edges near the bounds
        search_margin = 20

        # Refine top edge
        for y in range(max(0, top - search_margin), min(h, top + search_margin)):
            if np.sum(edges[y, left:right]) > (right - left) * 0.3:
                top = y
                break

        # Refine bottom edge
        for y in range(min(h - 1, bottom + search_margin), max(0, bottom - search_margin), -1):
            if np.sum(edges[y, left:right]) > (right - left) * 0.3:
                bottom = y
                break

        # Scale back to original image coordinates
        return {
            'top': int(top / scale_y),
            'bottom': int(bottom / scale_y),
            'left': int(left / scale_x),
            'right': int(right / scale_x),
        }

    except Exception as e:
        logger.warning(f'Edge refinement failed: {e}')
        return initial_bounds
