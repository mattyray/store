"""
Wall Plane Detection from Depth Maps.

Uses RANSAC plane fitting to identify the dominant wall plane
from a depth map generated by MiDaS.
"""
import logging
import numpy as np

logger = logging.getLogger(__name__)


def detect_wall_plane(
    depth_map: np.ndarray,
    image_width: int,
    image_height: int,
    min_confidence: float = 0.3,
) -> dict:
    """
    Detect the dominant wall plane from a depth map.

    Uses RANSAC to find the largest planar surface, which is typically
    the wall the user photographed.

    Args:
        depth_map: Depth map array (height, width) with values in [0, 1]
        image_width: Original image width
        image_height: Original image height
        min_confidence: Minimum confidence threshold

    Returns:
        Dictionary with:
        - bounds: {top, bottom, left, right} pixel coordinates
        - confidence: float between 0 and 1
        - mask: binary mask of wall pixels (optional)
    """
    try:
        from sklearn.linear_model import RANSACRegressor
        from scipy import ndimage
    except ImportError:
        logger.warning('sklearn/scipy not available. Using fallback detection.')
        return _fallback_detection(image_width, image_height)

    try:
        h, w = depth_map.shape

        # Create coordinate grids
        y_coords, x_coords = np.meshgrid(np.arange(h), np.arange(w), indexing='ij')

        # Flatten for processing
        points_x = x_coords.flatten()
        points_y = y_coords.flatten()
        points_z = depth_map.flatten()

        # Filter out invalid depth values (very close or very far)
        valid_mask = (points_z > 0.05) & (points_z < 0.95)
        valid_count = np.sum(valid_mask)

        if valid_count < 1000:
            logger.warning('Not enough valid depth points')
            return _fallback_detection(image_width, image_height)

        # Sample points for RANSAC (use subset for speed)
        sample_size = min(10000, valid_count)
        indices = np.where(valid_mask)[0]
        sample_indices = np.random.choice(indices, size=sample_size, replace=False)

        X = np.column_stack([
            points_x[sample_indices],
            points_y[sample_indices]
        ])
        z = points_z[sample_indices]

        # RANSAC plane fitting: z = ax + by + c
        # Residual threshold based on depth std deviation
        threshold = np.std(z) * 0.15

        ransac = RANSACRegressor(
            min_samples=0.3,
            residual_threshold=threshold,
            max_trials=100,
            random_state=42,
        )
        ransac.fit(X, z)

        # Get inlier mask for sampled points
        sample_inliers = ransac.inlier_mask_

        # Apply model to all valid points to get full inlier mask
        X_all = np.column_stack([
            points_x[valid_mask],
            points_y[valid_mask]
        ])
        z_all = points_z[valid_mask]
        predicted = ransac.predict(X_all)
        residuals = np.abs(z_all - predicted)
        full_inliers = residuals < threshold

        # Calculate confidence as percentage of inliers
        confidence = np.sum(full_inliers) / len(full_inliers)

        # Create wall mask
        wall_mask = np.zeros(h * w, dtype=bool)
        wall_mask[valid_mask] = full_inliers
        wall_mask = wall_mask.reshape(h, w)

        # Clean up mask with morphological operations
        wall_mask = ndimage.binary_closing(wall_mask, iterations=5)
        wall_mask = ndimage.binary_opening(wall_mask, iterations=3)
        wall_mask = ndimage.binary_fill_holes(wall_mask)

        # Find bounding box
        rows = np.any(wall_mask, axis=1)
        cols = np.any(wall_mask, axis=0)

        if not np.any(rows) or not np.any(cols):
            return _fallback_detection(image_width, image_height)

        rmin, rmax = np.where(rows)[0][[0, -1]]
        cmin, cmax = np.where(cols)[0][[0, -1]]

        # Scale bounds to original image size
        scale_x = image_width / w
        scale_y = image_height / h

        bounds = {
            'top': int(rmin * scale_y),
            'bottom': int(rmax * scale_y),
            'left': int(cmin * scale_x),
            'right': int(cmax * scale_x),
        }

        logger.info(f'Wall detected with confidence: {confidence:.2%}')

        return {
            'bounds': bounds,
            'confidence': float(confidence),
        }

    except Exception as e:
        logger.error(f'Wall detection failed: {e}')
        return _fallback_detection(image_width, image_height)


def _fallback_detection(image_width: int, image_height: int) -> dict:
    """
    Fallback wall detection when ML fails.
    Returns bounds covering most of the image with a margin.
    """
    margin_x = int(image_width * 0.1)
    margin_y = int(image_height * 0.1)

    return {
        'bounds': {
            'top': margin_y,
            'bottom': image_height - margin_y,
            'left': margin_x,
            'right': image_width - margin_x,
        },
        'confidence': 0.0,
    }


def refine_wall_bounds(
    depth_map: np.ndarray,
    initial_bounds: dict,
    image_width: int,
    image_height: int,
) -> dict:
    """
    Refine wall bounds using edge detection.

    This can be used to snap bounds to actual wall edges
    after initial detection or manual selection.

    Args:
        depth_map: Depth map array
        initial_bounds: Initial bounds to refine
        image_width: Original image width
        image_height: Original image height

    Returns:
        Refined bounds dictionary
    """
    try:
        import cv2
    except ImportError:
        return initial_bounds

    try:
        # Convert depth map to uint8 for edge detection
        depth_uint8 = (depth_map * 255).astype(np.uint8)

        # Apply Canny edge detection
        edges = cv2.Canny(depth_uint8, 50, 150)

        # Scale to original image size
        h, w = depth_map.shape
        scale_x = w / image_width
        scale_y = h / image_height

        # Convert bounds to depth map coordinates
        top = int(initial_bounds['top'] * scale_y)
        bottom = int(initial_bounds['bottom'] * scale_y)
        left = int(initial_bounds['left'] * scale_x)
        right = int(initial_bounds['right'] * scale_x)

        # Find edges near the bounds
        search_margin = 20

        # Refine top edge
        for y in range(max(0, top - search_margin), min(h, top + search_margin)):
            if np.sum(edges[y, left:right]) > (right - left) * 0.3:
                top = y
                break

        # Refine bottom edge
        for y in range(min(h - 1, bottom + search_margin), max(0, bottom - search_margin), -1):
            if np.sum(edges[y, left:right]) > (right - left) * 0.3:
                bottom = y
                break

        # Scale back to original image coordinates
        return {
            'top': int(top / scale_y),
            'bottom': int(bottom / scale_y),
            'left': int(left / scale_x),
            'right': int(right / scale_x),
        }

    except Exception as e:
        logger.warning(f'Edge refinement failed: {e}')
        return initial_bounds
